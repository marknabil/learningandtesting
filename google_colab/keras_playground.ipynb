{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"keras_playground.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"7-D1krLTPP46","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"a8d94058-7518-4da3-b1c6-0618451ec261","executionInfo":{"status":"ok","timestamp":1537623890697,"user_tz":-120,"elapsed":10185,"user":{"displayName":"mark nabil","photoUrl":"","userId":"04731080965943929871"}}},"cell_type":"code","source":["# Edited example of keras-team mnist example of how to use the confusion matrix callback\n","\n","'''Trains a simple convnet on the MNIST dataset.\n","Gets to 99.25% test accuracy after 12 epochs\n","(there is still a lot of margin for parameter tuning).\n","16 seconds per epoch on a GRID K520 GPU.\n","'''\n","\n","from __future__ import print_function\n","import keras\n","from keras.datasets import mnist\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Flatten\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras import backend as K\n","from keras.callbacks import LambdaCallback\n","\n","\n","from sklearn.metrics import classification_report, confusion_matrix\n"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"metadata":{"id":"xf8yUJW1PWzn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"outputId":"d5232ae5-ad12-450e-b12e-1b2362ab653f","executionInfo":{"status":"ok","timestamp":1537516887374,"user_tz":-120,"elapsed":1540,"user":{"displayName":"mark nabil","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100349270716175055813"}}},"cell_type":"code","source":["batch_size = 128\n","num_classes = 10\n","epochs = 5\n","\n","# input image dimensions\n","img_rows, img_cols = 28, 28\n","\n","# the data, shuffled and split between train and test sets\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","\n","if K.image_data_format() == 'channels_first':\n","    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n","    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n","    input_shape = (1, img_rows, img_cols)\n","else:\n","    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n","    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n","    input_shape = (img_rows, img_cols, 1)\n","\n","x_train = x_train.astype('float32')\n","x_test = x_test.astype('float32')\n","x_train /= 255\n","x_test /= 255\n","print('x_train shape:', x_train.shape)\n","print(x_train.shape[0], 'train samples')\n","print(x_test.shape[0], 'test samples')\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["x_train shape: (60000, 28, 28, 1)\n","60000 train samples\n","10000 test samples\n"],"name":"stdout"}]},{"metadata":{"id":"6T6_FHD1wHHp","colab_type":"code","colab":{}},"cell_type":"code","source":["def calculate_label_confusion(matrix,label):\n","    tp = matrix[:,label,label]\n","    fn = matrix[:,label,:].sum(axis=1) - tp\n","    fp = matrix[:,:,label].sum(axis=1) - tp\n","    tn = matrix[:,:,:].sum(axis=(1,2)) - (fn+fp+tp)\n","    return tp,tn,fp,fn\n","\n","def precision(tp,tn,fp,fn):\n","    return tp/(tp+fp)\n","\n","def recall(tp,tn,fp,fn):\n","    return tp/(tp+fn)\n","\n","def accuracy(tp,tn,fp,fn):\n","    return (tp+tn)/(tp+tn+fp+fn)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hsasBVa_v7Sa","colab_type":"code","colab":{}},"cell_type":"code","source":["def confusion_matrix_cell(true_class, pred_class):\n","    \"\"\"\n","    Creates a metric that collects the value for a single cells of the confusion matrix\n","    :param true_class:\n","    :param pred_class:\n","    :return: Keras metric\n","    \"\"\"\n","\n","    def confusion(y_true, y_pred):\n","        \"\"\"\n","        Collects the samples predicted as pred_class where its true class is true_class\n","        :param y_true:\n","        :param y_pred:\n","        :return: the number of predictions as mentioned above\n","        \"\"\"\n","        # Calculate the label from one-hot encoding\n","        pred_class_label = K.argmax(y_pred, axis=-1)\n","        true_class_label = K.argmax(y_true, axis=-1)\n","\n","        # Create a mask representing where the prediction is pred_class and the true class is true_class\n","        pred_mask = K.equal(pred_class_label, pred_class)\n","        true_mask = K.equal(true_class_label, true_class)\n","        mask = tf.logical_and(pred_mask, true_mask)\n","\n","        # Get the total number of occurences\n","        occurrences = K.sum(K.cast(mask, 'int32'), axis=0)\n","        return occurrences\n","\n","    return confusion"],"execution_count":0,"outputs":[]},{"metadata":{"id":"u9973yjkwPiJ","colab_type":"code","colab":{}},"cell_type":"code","source":["from keras.callbacks import Callback\n","class ConfusionMatrix(Callback):\n","    \"\"\"\n","    A callback used to collect confusion matrix cell values.\n","    Is appropriate for multi-class problems.\n","    \"\"\"\n","    def __init__(self,num_labels,matrix_saver=None,val_matrix_saver=None):\n","        \"\"\"\n","        Initializes the callback\n","        :param num_labels: The number of classes\n","        :param matrix_saver: Should save the confusion matrix for each epoch\n","        \"\"\"\n","        super(ConfusionMatrix, self).__init__()\n","        self.num_labels = num_labels\n","        self.matrix_saver = matrix_saver\n","        self.val_matrix_saver = val_matrix_saver\n","        self.metric_prefix = 'confusion_'\n","        self.val_metric_prefix = 'val_confusion_'\n","\n","    def on_epoch_begin(self, epoch, logs=None):\n","        \"\"\"\n","        Reset confusion matrix\n","        :param epoch:\n","        :param logs:\n","        :return:\n","        \"\"\"\n","        self.matrix = np.zeros((self.num_labels,self.num_labels))\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        \"\"\"\n","        Saves confusion matrix and validation confusion matrix.\n","        IMPORTANT NOTE: Notice that the last batch in the validation dataset may cause\n","        wrong statistics (since keras returns the average)\n","        :param epoch:\n","        :param logs:\n","        :return:\n","        \"\"\"\n","        #Save the confusion matrix for training.\n","        if self.matrix_saver is not None:\n","            self.matrix_saver(self.matrix/self.matrix.sum())\n","\n","        # Saves the confusion matrix for validation.\n","        if self.val_matrix_saver is not None:\n","            self.matrix = np.zeros((self.num_labels,self.num_labels))\n","            self.collect_values(logs,self.val_metric_prefix)\n","            self.val_matrix_saver(self.matrix/self.matrix.sum())\n","\n","    def on_batch_end(self, batch, logs=None):\n","        # Collect value for each of the confusion matrix cells\n","        self.collect_values(logs,self.metric_prefix)\n","\n","    def collect_values(self,logs,metric_prefix):\n","        \"\"\"\n","        Collects all the values for the confusion matrix\n","        :param logs:\n","        :param metric_prefix:\n","        :return:\n","        \"\"\"\n","        for i in range(self.num_labels):\n","            for j in range(self.num_labels):\n","                self.collect_value(logs,metric_prefix,i,j)\n","\n","    def collect_value(self,logs,metric_prefix,i,j):\n","        \"\"\"\n","        Collects from logs the value for cell (i,j) in the confusion matrix\n","        :param logs: Keras logs dictionary object\n","        :param metric_prefix: The prefix of the metric collected up to the cell number\n","        :param i: true class\n","        :param j: predicted class\n","        :return:\n","        \"\"\"\n","        metric_name = metric_prefix + str(i*self.num_labels + j + 1)\n","        self.matrix[i,j] += logs[metric_name]\n","\n","    def generate_metrics(self):\n","        \"\"\"\n","        Creates all metrics needed for creating the confusion matrix\n","        :return: A list of metrics representing the confusion matrix cells\n","        \"\"\"\n","        return [confusion_matrix_cell(i, j) for i in range(self.num_labels) for j in range(self.num_labels)]\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"tGx-ge5PPZf6","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","# convert class vectors to binary class matrices\n","y_train = keras.utils.to_categorical(y_train, num_classes)\n","y_test = keras.utils.to_categorical(y_test, num_classes)\n","\n","model = Sequential()\n","model.add(Conv2D(32, kernel_size=(3, 3),\n","                 activation='relu',\n","                 input_shape=input_shape))\n","model.add(Conv2D(64, (3, 3), activation='relu'))\n","model.add(MaxPooling2D(pool_size=(2, 2)))\n","model.add(Dropout(0.25))\n","model.add(Flatten())\n","model.add(Dense(128, activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(Dense(num_classes, activation='softmax'))\n","\n","batch_print_callback = LambdaCallback(on_epoch_end=lambda epoch, logs: print(logs))\n","\n","'''\n","my_confusion = confusion_matrix(10,print,print)\n","confusion_metrics = my_confusion.generate_metrics()\n","'''\n","\n","my_confusion = ConfusionMatrix(10,print,print)\n","confusion_metrics = my_confusion.generate_metrics()\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"t0y2XSSkJYGo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"95e4297f-7c84-448f-f6ae-d2b9fd9dd452","executionInfo":{"status":"ok","timestamp":1537523806586,"user_tz":-120,"elapsed":490,"user":{"displayName":"mark nabil","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100349270716175055813"}}},"cell_type":"code","source":["\n","type(my_confusion)\n"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["__main__.ConfusionMatrix"]},"metadata":{"tags":[]},"execution_count":14}]},{"metadata":{"id":"jYM5G6rkJK9S","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":880},"outputId":"d5e632a0-6271-4174-cfb4-e1a8c079a16f","executionInfo":{"status":"error","timestamp":1537523811032,"user_tz":-120,"elapsed":527,"user":{"displayName":"mark nabil","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100349270716175055813"}}},"cell_type":"code","source":["model.compile(loss=keras.losses.categorical_crossentropy,\n","              optimizer=keras.optimizers.Adadelta(),\n","              metrics=['accuracy']+confusion_metrics)\n","\n","model.fit(x_train, y_train,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          validation_data=(x_test, y_test),\n","          callbacks=[batch_print_callback,my_confusion],\n","          verbose=0)\n","\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('Test loss:', score[0])\n","print('Test accuracy:', score[1])"],"execution_count":15,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-c35667e58a55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.compile(loss=keras.losses.categorical_crossentropy,\n\u001b[1;32m      2\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdadelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m               metrics=['accuracy']+confusion_metrics)\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m model.fit(x_train, y_train,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    861\u001b[0m                            \u001b[0mweighted_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweighted_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m                            \u001b[0mtarget_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m                            **kwargs)\n\u001b[0m\u001b[1;32m    864\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    934\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_updates\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmetric_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 936\u001b[0;31m                 \u001b[0mhandle_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m                 \u001b[0mhandle_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_weighted_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mhandle_metrics\u001b[0;34m(metrics, weights)\u001b[0m\n\u001b[1;32m    912\u001b[0m                             metric_result = weighted_metric_fn(y_true, y_pred,\n\u001b[1;32m    913\u001b[0m                                                                \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m                                                                mask=masks[i])\n\u001b[0m\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m                         \u001b[0;31m# Append to self.metrics_names, self.metric_tensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mweighted\u001b[0;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[1;32m    427\u001b[0m         \"\"\"\n\u001b[1;32m    428\u001b[0m         \u001b[0;31m# score_array has ndim >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m         \u001b[0mscore_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m             \u001b[0;31m# Cast the mask to floatX to avoid float64 upcasting in Theano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-44e295fe1215>\u001b[0m in \u001b[0;36mconfusion\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mpred_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_class_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mtrue_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_class_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;31m# Get the total number of occurences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"]}]}]}
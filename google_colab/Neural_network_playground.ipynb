{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Neural_network_playground.ipynb","version":"0.3.2","views":{},"default_view":{},"provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"fUFcM4YdbDmk","colab_type":"text"},"cell_type":"markdown","source":["followin the blog post : [link text](https://towardsdatascience.com/how-to-build-your-own-neural-network-from-scratch-in-python-68998a08e4f6)"]},{"metadata":{"id":"QgfCQs2Vs_-9","colab_type":"text"},"cell_type":"markdown","source":["Neural Networks consist of the following components\n","\n","*   An input layer, x\n","*   An arbitrary amount of hidden layers\n","*  An output layer, ŷ\n","* A set of weights and biases between each layer, W and b\n","* A choice of activation function for each hidden layer, σ. In this tutorial, we’ll use a Sigmoid activation function."]},{"metadata":{"id":"iIm8idhBbKKi","colab_type":"code","colab":{"autoexec":{"startup":false,"wait_interval":0},"base_uri":"https://localhost:8080/","height":90},"outputId":"74eccc9e-83f5-461b-a404-00dd54195da2","executionInfo":{"status":"ok","timestamp":1527441161645,"user_tz":-120,"elapsed":507,"user":{"displayName":"mark nabil","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"100349270716175055813"}}},"cell_type":"code","source":["import numpy as np\n","\n","def sigmoid(x):\n","    return 1.0/(1+ np.exp(-x))\n","\n","def sigmoid_derivative(x):\n","    return x * (1.0 - x)\n","\n","class NeuralNetwork:\n","    def __init__(self, x, y):\n","        self.input      = x\n","        self.weights1   = np.random.rand(self.input.shape[1],4) \n","        self.weights2   = np.random.rand(4,1)                 \n","        self.y          = y\n","        self.output     = np.zeros(self.y.shape)\n","\n","    def feedforward(self):\n","        self.layer1 = sigmoid(np.dot(self.input, self.weights1))\n","        self.output = sigmoid(np.dot(self.layer1, self.weights2))\n","\n","    def backprop(self):\n","        # application of the chain rule to find derivative of the loss function with respect to weights2 and weights1\n","        d_weights2 = np.dot(self.layer1.T, (2*(self.y - self.output) * sigmoid_derivative(self.output)))\n","        d_weights1 = np.dot(self.input.T,  (np.dot(2*(self.y - self.output) * sigmoid_derivative(self.output), self.weights2.T) * sigmoid_derivative(self.layer1)))\n","\n","        # update the weights with the derivative (slope) of the loss function\n","        self.weights1 += d_weights1\n","        self.weights2 += d_weights2\n","        \n","if __name__ == \"__main__\":\n","    X = np.array([[0,0,1],\n","                  [0,1,1],\n","                  [1,0,1],\n","                  [1,1,1]])\n","    y = np.array([[0],[1],[1],[0]])\n","    nn = NeuralNetwork(X,y)\n","\n","    for i in range(1500):\n","        nn.feedforward()\n","        nn.backprop()\n","\n","    print(nn.output)"],"execution_count":4,"outputs":[{"output_type":"stream","text":["[[0.00932031]\n"," [0.97153252]\n"," [0.97170191]\n"," [0.03530835]]\n"],"name":"stdout"}]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of sem-seg.ipynb","version":"0.3.2","provenance":[{"file_id":"https://github.com/HemaZ/sem-seg/blob/master/sem_seg.ipynb","timestamp":1535912116647}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"jqWZROWvfkAM","colab_type":"text"},"cell_type":"markdown","source":["## Semantic Segmentation Project\n","\n","Introduction \n","\n","In this project, The model will label the pixels of a road in images using a Fully Convolutional Network (FCN) and a pre-trained VGG16 model.\n","\n","### Dataset\n","\n","[Kitti Road dataset](http://www.cvlibs.net/datasets/kitti/eval_road.php) which can be downloaded from [here](http://www.cvlibs.net/download.php?file=data_road.zip)\n","\n","### Architecture\n","\n","The model is a Fully Convolutional Network (You can Check this paper for more info [Link](https://people.eecs.berkeley.edu/~jonlong/long_shelhamer_fcn.pdf))\n","\n","which is built above a pre-trained VGG 16 model, by removing the last layer and converting it by a 1x1 convolution with 2 Classes as the depth (Road, Not Road). Then Using Upsample to restore the spatial dimensions of the input image. Some skip connections between VGG layers and the new Layers were used to improve the Performance.\n","\n","### Training\n","\n","The hyperparameters used for training are:\n","\n","-   keep_prob: 0.5\n","    \n","-   learning_rate: 0.001\n","    \n","-   epochs: 60\n","    \n","-   batch_size: 5\n","    \n","\n","The model was Trained using Google Colab GPU Runtime. it took about 1-2 hours of Training.\n","\n","### Results\n","\n","After the 60 epochs the model reached 1.4 as epoch loss.\n","\n","### Setup\n","\n","##### Frameworks and Packages\n","\n","helper.py and the Pre-Trained VGG model is provided by Udacity. Please check their github Repository from [here](https://github.com/udacity/CarND-Semantic-Segmentation)\n","\n","Make sure you have the following is installed:\n","\n","-   [Python 3](https://www.python.org/)\n","    \n","-   [TensorFlow](https://www.tensorflow.org/)\n","    \n","-   [NumPy](http://www.numpy.org/)\n","    \n","-   [SciPy](https://www.scipy.org/)"]},{"metadata":{"id":"hQbH-Ou5ustr","colab_type":"code","colab":{}},"cell_type":"code","source":["import tensorflow as tf "],"execution_count":0,"outputs":[]},{"metadata":{"id":"M5kjTQKWAgn8","colab_type":"code","colab":{}},"cell_type":"code","source":["num_classes = 2\n","image_shape = (160, 576)\n","data_dir = './data'\n","runs_dir = './runs'\n","EPOCHS=60\n","BATCH_SIZE=5"],"execution_count":0,"outputs":[]},{"metadata":{"id":"K-DljhDxWg_4","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":254},"outputId":"f8fa61d2-0dc7-4b35-c9b5-687b8c866a07"},"cell_type":"code","source":["## Execute this cell for the first time only to download dataset and VGG weights\n","!wget https://s3.eu-central-1.amazonaws.com/avg-kitti/data_road.zip\n","!unzip data_road.zip\n","helper.maybe_download_pretrained_vgg(data_dir)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2018-09-02 21:53:23--  https://s3.eu-central-1.amazonaws.com/avg-kitti/data_road.zip\r\n","Resolving s3.eu-central-1.amazonaws.com (s3.eu-central-1.amazonaws.com)... 52.219.73.0\n","Connecting to s3.eu-central-1.amazonaws.com (s3.eu-central-1.amazonaws.com)|52.219.73.0|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 470992343 (449M) [application/zip]\n","Saving to: ‘data_road.zip.7’\n","\n","data_road.zip.7     100%[===================>] 449.17M  19.1MB/s    in 29s     \n","\n","2018-09-02 21:53:52 (15.5 MB/s) - ‘data_road.zip.7’ saved [470992343/470992343]\n","\n","Archive:  data_road.zip\n","replace data_road/training/image_2/umm_000032.png? [y]es, [n]o, [A]ll, [N]one, [r]ename: "],"name":"stdout"}]},{"metadata":{"id":"xprKYaVFuV4M","colab_type":"code","colab":{}},"cell_type":"code","source":["def load_vgg(sess,path):\n","  model=tf.saved_model.loader.load(sess,['vgg16'],path)\n","  graph=tf.get_default_graph()\n","  graph = tf.get_default_graph()\n","  image_input = graph.get_tensor_by_name('image_input:0')\n","  keep_prob = graph.get_tensor_by_name('keep_prob:0')\n","  layer3 = graph.get_tensor_by_name('layer3_out:0')\n","  layer4 = graph.get_tensor_by_name('layer4_out:0')\n","  layer7 = graph.get_tensor_by_name('layer7_out:0')\n","\n","  return image_input, keep_prob, layer3, layer4, layer7"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VI2YS-hJwL3q","colab_type":"code","colab":{}},"cell_type":"code","source":["def layers(layer3, layer4, layer7,num_classes):\n","  fcn8=tf.layers.conv2d(layer7,filters=num_classes,kernel_size=1,name='fcn8')\n","  \n","  fcn9 = tf.layers.conv2d_transpose(fcn8, filters=layer4.get_shape().as_list()[-1],\n","    kernel_size=4, strides=(2, 2), padding='SAME', name=\"fcn9\")\n","  \n","  fcn9_skip=tf.add(fcn9,layer4,name=\"fcn9_plus_vgg_layer4\")\n","  \n","  fcn10 = tf.layers.conv2d_transpose(fcn9_skip, filters=layer3.get_shape().as_list()[-1],\n","    kernel_size=4, strides=(2, 2), padding='SAME', name=\"fcn10_conv2d\")  \n","  fc10_skip=tf.add(fcn10,layer3,name='fcn10_plus_vgg_layer3')\n","  \n","  fcn11 = tf.layers.conv2d_transpose(fc10_skip, filters=num_classes,\n","    kernel_size=16, strides=(8, 8), padding='SAME', name=\"fcn11\")\n","  \n","  return fcn11"],"execution_count":0,"outputs":[]},{"metadata":{"id":"s857E8IF1hgo","colab_type":"code","colab":{}},"cell_type":"code","source":["def optimize(last_layer,correct_label,lr,num_classes):\n","  \n","  logits = tf.reshape(last_layer, (-1, num_classes), name=\"fcn_logits\")\n","  correct_label_reshaped = tf.reshape(correct_label, (-1, num_classes))\n","  cross_entropy = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=correct_label_reshaped[:])\n","  # Take mean for total loss\n","  loss_op = tf.reduce_mean(cross_entropy, name=\"fcn_loss\")\n","  train_op = tf.train.AdamOptimizer(learning_rate=lr).minimize(loss_op, name=\"fcn_train_op\")\n","  return logits, train_op, loss_op"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_qoGuniP2j3r","colab_type":"code","colab":{}},"cell_type":"code","source":["def train_nn(sess, epochs, batch_size, get_batches_fn, train_op,\n","             cross_entropy_loss, input_image,\n","             correct_label, keep_prob, learning_rate):\n","\n","  keep_prob_value = 0.5\n","  learning_rate_value = 0.001\n","  for epoch in range(epochs):\n","      # Create function to get batches\n","      total_loss = 0\n","      for X_batch, gt_batch in get_batches_fn(batch_size):\n","\n","          loss, _ = sess.run([cross_entropy_loss, train_op],\n","          feed_dict={input_image: X_batch, correct_label: gt_batch,\n","          keep_prob: keep_prob_value, learning_rate:learning_rate_value})\n","          print(\"Batch Loss = {:.5f}\".format(loss))\n","          total_loss += loss;\n","\n","      print(\"EPOCH {} ...\".format(epoch + 1))\n","      print(\"Total Loss = {:.3f}\".format(total_loss))\n","      print()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7tHGSVUD69uH","colab_type":"code","colab":{}},"cell_type":"code","source":["import helper\n","tf.reset_default_graph()\n","# A function to get batches\n","get_batches_fn = helper.gen_batch_function(\"data_road/training\", image_shape)\n","session=tf.Session()\n","\n","vgg_path = os.path.join(data_dir, 'vgg')\n","# Returns the three layers, keep probability and input layer from the vgg architecture\n","image_input, keep_prob, layer3, layer4, layer7 = load_vgg(session, vgg_path)\n","\n","# The resulting network architecture from adding a decoder on top of the given vgg model\n","model_output = layers(layer3, layer4, layer7, num_classes)\n","\n","# Returns the output logits, training operation and cost operation to be used\n","# - logits: each row represents a pixel, each column a class\n","# - train_op: function used to get the right parameters to the model to correctly label the pixels\n","# - cross_entropy_loss: function outputting the cost which we are minimizing, lower cost should yield higher accuracy\n","\n","\n","correct_label = tf.placeholder(tf.int32, [None, None, None, num_classes], name='correct_label')\n","learning_rate = tf.placeholder(tf.float32, name='learning_rate')\n","\n","logits, train_op, cross_entropy_loss = optimize(model_output, correct_label, learning_rate, num_classes)\n","\n","# Initialize all variables\n","session.run(tf.global_variables_initializer())\n","session.run(tf.local_variables_initializer())\n","\n","print(\"Model build successful, starting training\")\n","\n","# Train the neural network\n","train_nn(session, EPOCHS, BATCH_SIZE, get_batches_fn, \n","         train_op, cross_entropy_loss, image_input,\n","         correct_label, keep_prob, learning_rate)\n","\n","# Run the model with the test images and save each painted output image (roads painted Violet)\n","helper.save_inference_samples(runs_dir, \"./\", session, image_shape, logits, keep_prob, image_input)\n","\n","print(\"All done!\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"UTlJy5jTun50","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"0ca6d098-f050-491f-813c-e0ccb7bcedac"},"cell_type":"code","source":["## Save The model to Restore it Later\n","saver = tf.train.Saver()\n","saver.restore(session, \"./tmp/model.ckpt\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from ./tmp/model.ckpt\n"],"name":"stdout"}]},{"metadata":{"id":"6F4FjxnTymsO","colab_type":"code","colab":{},"outputId":"8aa9772c-7ca8-4f88-b1a5-2a1e0a978394"},"cell_type":"code","source":["## You can zip the Test Output using this Cell then upolad it to your google drive using the next Cell\n","!zip -r img08.zip ./runs/1535902746.2466056"],"execution_count":0,"outputs":[{"output_type":"stream","text":["\tzip warning: name not matched: ./runs/1535902746.2466056\r\n","\r\n","zip error: Nothing to do! (try: zip -r img08.zip . -i ./runs/1535902746.2466056)\r\n"],"name":"stdout"}]},{"metadata":{"id":"XqLElesz_wvd","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"a2219dc1-b5c7-427f-8111-b50388a1793b"},"cell_type":"code","source":["# Install the PyDrive wrapper & import libraries.\n","# This only needs to be done once in a notebook.\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","# Authenticate and create the PyDrive client.\n","# This only needs to be done once in a notebook.\n","auth.authenticate_user()\n","gauth = GoogleAuth()\n","gauth.credentials = GoogleCredentials.get_application_default()\n","drive = GoogleDrive(gauth)\n","\n","# Create & upload a file.\n","uploaded = drive.CreateFile({'title': 'img08.zip'})\n","uploaded.SetContentFile('img08.zip')\n","uploaded.Upload()\n","print('Uploaded file with ID {}'.format(uploaded.get('id')))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Uploaded file with ID 1n52Jai_cHTlMdOkyFSwOOKe-8nfXvj47\n"],"name":"stdout"}]},{"metadata":{"id":"cdcazTGAksyw","colab_type":"code","colab":{}},"cell_type":"code","source":["files.download('./runs/img0-out/image-027.png')"],"execution_count":0,"outputs":[]},{"metadata":{"id":"X8rv0rZkp9fe","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}